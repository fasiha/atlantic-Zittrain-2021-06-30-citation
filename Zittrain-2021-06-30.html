<article class="ArticleWrapper_root__Q8ty6 ArticleWrapper_standard__178wv">
  <header class="ArticleHeader_root__OM7TZ">
    <div class="ArticleLockup_root__3J5Am">
      <div class="ArticleRubric_root__3CjTZ" id="rubric"><a class="ArticleRubric_link__1eWl6"
          href="https://www.theatlantic.com/technology/" data-action="click link - section rubric"
          data-label="https://www.theatlantic.com/technology/">Technology</a></div>
      <h1 class="ArticleTitle_root__1SxDD">The Internet Is Rotting</h1>
      <p class="ArticleDek_root__1_tnX">Too much has been lost already. The glue that holds humanity’s knowledge
        together is coming undone.</p>
      <div class="ArticleBylines_root__NaEL5">
        <address id="byline">By <a href="https://www.theatlantic.com/author/jonathan-zittrain/"
            data-action="click author - byline"
            data-label="https://www.theatlantic.com/author/jonathan-zittrain/">Jonathan Zittrain</a></address>
      </div>
    </div>
    <div class="ArticleLeadArt_root__gi0oh">
      <figure class="ArticleLeadFigure_root__2I1Rw ArticleLeadFigure_standard__1MSBS">
        <div class="ArticleLeadFigure_media__1WfvY"><img
            src="https://cdn.theatlantic.com/thumbor/x0rTnEzjYCF0gUwecYjEfjv8OMY=/0x0:4800x2700/960x540/media/img/mt/2021/06/Untitled_10_1/original.gif"
            srcset="https://cdn.theatlantic.com/thumbor/n2wlZh3TtTGoGl0mdCXVpo5l9w4=/0x0:4800x2700/750x422/media/img/mt/2021/06/Untitled_10_1/original.gif 750w, https://cdn.theatlantic.com/thumbor/pfVA6VW2KHL7hVFoyNlxEVSip-A=/0x0:4800x2700/828x466/media/img/mt/2021/06/Untitled_10_1/original.gif 828w, https://cdn.theatlantic.com/thumbor/x0rTnEzjYCF0gUwecYjEfjv8OMY=/0x0:4800x2700/960x540/media/img/mt/2021/06/Untitled_10_1/original.gif 960w, https://cdn.theatlantic.com/thumbor/T4-J90Bgpatvbzeixy_ScMYUjXI=/0x0:4800x2700/976x549/media/img/mt/2021/06/Untitled_10_1/original.gif 976w, https://cdn.theatlantic.com/thumbor/3hjlDD7KFFpjNUMaxYhyZVD63T0=/0x0:4800x2700/1952x1098/media/img/mt/2021/06/Untitled_10_1/original.gif 1952w"
            alt="Computer with screen glitching out" class="Image_root__J8Wlz ArticleLeadArt_image__M6-k6"
            sizes="100vw, (min-width: 976px) 976px" width="960" height="540"></div>
        <figcaption class="ArticleLeadFigure_caption__5K7cv ArticleLeadFigure_standardCaption__CElht">Getty / Valerie
          Chiang</figcaption>
      </figure>
    </div>
    <div class="ArticleUtilityBar_root__fMTYg"><time class="ArticleTimestamp_root__3Icpi"
        datetime="2021-06-30T11:30:00Z">June 30, 2021</time>
      <div class="ArticleShare_root__2i9Gh"><button class="ArticleShare_shareButton__1KWQr" aria-haspopup="true"
          aria-controls="expanded-share-kit" aria-expanded="false" aria-label="Open Share Menu"
          data-action="click share - expand">Share</button></div>
    </div>
  </header>
  <section class="ArticleBody_root__17rER">
    <p class="ArticleParagraph_root__2QM08 ArticleParagraph_dropcap__3I841">Sixty years ago the futurist Arthur C.
      Clarke <a href="https://perma.cc/5JNR-6RBW">observed</a> that any sufficiently advanced technology is
      indistinguishable from magic. The internet—how we both communicate with one another and together preserve the
      intellectual products of human civilization—fits Clarke’s observation well. In Steve Jobs’s words, “<a
        href="https://www.youtube.com/watch?v=qmPq00jelpc">it just works</a>,” as readily as clicking, tapping, or
      speaking. And every bit as much aligned with the vicissitudes of magic, when the internet doesn’t work, the
      reasons are typically so arcane that explanations for it are about as useful as trying to pick apart a failed
      spell.</p>
    <gpt-ad class="GptAd_root__nza6l HousePromo_root__2jjMC HousePromo_swanInjected__QxjKZ" format="promo"
      sizes-at-0="house"></gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Underpinning our vast and simple-seeming digital networks are technologies
      that, if they hadn’t already been invented, probably wouldn’t unfold the same way again. They are artifacts of a
      very particular circumstance, and it’s unlikely that in an alternate timeline they would have been designed the
      same way.</p>
    <p class="ArticleParagraph_root__2QM08">The internet’s distinct architecture arose from a distinct constraint and a
      distinct freedom: First, its academically minded designers didn’t have or expect to raise massive amounts of
      capital to build the network; and second, they didn’t want or expect to make money from their invention.</p>
    <p class="ArticleParagraph_root__2QM08">The internet’s framers thus had no money to simply roll out a uniform
      centralized network the way that, for example, FedEx metabolized a capital outlay of <a
        href="https://perma.cc/U4F5-RWJA">tens of millions of dollars</a> to deploy liveried planes, trucks, people, and
      drop-off boxes, creating a single point-to-point delivery system. Instead, they settled on the equivalent of rules
      for how to bolt existing networks together.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-1" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Rather than a single centralized network modeled after the legacy telephone
      system, operated by a government or a few massive utilities, the internet was designed to allow any device
      anywhere to interoperate with any other device, allowing any provider able to bring whatever networking capacity
      it had to the growing party. And because the network’s creators did not mean to monetize, much less monopolize,
      any of it, the key was for desirable content to be provided naturally by the network’s users, some of whom would
      act as content producers or hosts, setting up watering holes for others to frequent.</p>
    <div class="ArticleRelatedContentModule_root__1MN9q">
      <div class="ArticleRelatedContentModule_notchedModule__EW8zS">
        <section class="ArticleRelatedContentList_root__3X5xb">
          <h2 class="ArticleRelatedContentList_heading__1ehAy">Recommended Reading</h2>
          <ul class="ArticleRelatedContentList_list__1sKXb">
            <li class="ArticleRelatedContentList_listItem__VqE3T">
              <div class="ArticleRelatedContentList_content__1aQb6"
                data-view-action="view link - recommended reading 1 - item 1"
                data-view-label="https://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041/">
                <figure class="ArticleRelatedContentList_figure__1M8iQ"><a class="ArticleRelatedContentList_link__mi83W"
                    href="https://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041/"
                    title="Read More: The Internet's Original Sin"
                    data-action="click link - recommended reading - image 1"
                    data-label="https://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041/">
                    <picture class="ArticleRelatedContentList_picture__Mv-vI"><img
                        src="https://cdn.theatlantic.com/thumbor/hXgclO5uK1ACUC-SIIDTTGaaTOY=/188x0:1210x1022/90x90/media/img/mt/2018/06/05752r/original.jpg"
                        srcset="https://cdn.theatlantic.com/thumbor/hXgclO5uK1ACUC-SIIDTTGaaTOY=/188x0:1210x1022/90x90/media/img/mt/2018/06/05752r/original.jpg 90w, https://cdn.theatlantic.com/thumbor/rHe4oXKZFI1E99J7HSYd2ORH5Fg=/188x0:1210x1022/180x180/media/img/mt/2018/06/05752r/original.jpg 180w"
                        alt="" loading="lazy"
                        class="Image_root__J8Wlz Image_lazy__1w_jB Image_loaded__3uNg2 ArticleRelatedContentList_image__27aRm"
                        width="90" height="90"></picture>
                  </a></figure>
                <div class="ArticleRelatedContentList_textWrapper__3ABd5">
                  <h3 class="ArticleRelatedContentList_title__3A31L"><a class="ArticleRelatedContentList_link__mi83W"
                      href="https://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041/"
                      data-action="click link - recommended reading - title 1"
                      data-label="https://www.theatlantic.com/technology/archive/2014/08/advertising-is-the-internets-original-sin/376041/">The
                      Internet's Original Sin</a></h3>
                  <address class="ArticleRelatedContentList_byline__2z0Zo"><a
                      href="https://www.theatlantic.com/author/ethan-zuckerman/"
                      data-action="click link - recommended reading - author 1"
                      data-label="https://www.theatlantic.com/author/ethan-zuckerman/"><span>Ethan Zuckerman</span></a>
                  </address>
                </div>
              </div>
            </li>
            <li class="ArticleRelatedContentList_listItem__VqE3T">
              <div class="ArticleRelatedContentList_content__1aQb6"
                data-view-action="view link - recommended reading 1 - item 2"
                data-view-label="https://www.theatlantic.com/technology/archive/2020/12/facebook-doomsday-machine/617384/">
                <figure class="ArticleRelatedContentList_figure__1M8iQ"><a class="ArticleRelatedContentList_link__mi83W"
                    href="https://www.theatlantic.com/technology/archive/2020/12/facebook-doomsday-machine/617384/"
                    title="Read More: Facebook Is a Doomsday Machine"
                    data-action="click link - recommended reading - image 2"
                    data-label="https://www.theatlantic.com/technology/archive/2020/12/facebook-doomsday-machine/617384/">
                    <picture class="ArticleRelatedContentList_picture__Mv-vI"><img
                        src="https://cdn.theatlantic.com/thumbor/DBty1GQo1dsF1htN0uMTzKpIF_E=/438x0:1563x1125/90x90/media/img/mt/2020/12/facebookdoomsday2/original.jpg"
                        srcset="https://cdn.theatlantic.com/thumbor/DBty1GQo1dsF1htN0uMTzKpIF_E=/438x0:1563x1125/90x90/media/img/mt/2020/12/facebookdoomsday2/original.jpg 90w, https://cdn.theatlantic.com/thumbor/e7DuCytqBRN8jACxG1ewYVj-0F8=/438x0:1563x1125/180x180/media/img/mt/2020/12/facebookdoomsday2/original.jpg 180w"
                        alt="The Facebook logo in the center of a radiation warning symbol" loading="lazy"
                        class="Image_root__J8Wlz Image_lazy__1w_jB Image_loaded__3uNg2 ArticleRelatedContentList_image__27aRm"
                        width="90" height="90"></picture>
                  </a></figure>
                <div class="ArticleRelatedContentList_textWrapper__3ABd5">
                  <h3 class="ArticleRelatedContentList_title__3A31L"><a class="ArticleRelatedContentList_link__mi83W"
                      href="https://www.theatlantic.com/technology/archive/2020/12/facebook-doomsday-machine/617384/"
                      data-action="click link - recommended reading - title 2"
                      data-label="https://www.theatlantic.com/technology/archive/2020/12/facebook-doomsday-machine/617384/">Facebook
                      Is a Doomsday Machine</a></h3>
                  <address class="ArticleRelatedContentList_byline__2z0Zo"><a
                      href="https://www.theatlantic.com/author/adrienne-lafrance/"
                      data-action="click link - recommended reading - author 2"
                      data-label="https://www.theatlantic.com/author/adrienne-lafrance/"><span>Adrienne
                        LaFrance</span></a></address>
                </div>
              </div>
            </li>
            <li class="ArticleRelatedContentList_listItem__VqE3T">
              <gpt-ad
                class="GptAd_root__nza6l s-native s-native--short-title s-native--standard s-native--small s-native--streamline"
                lazy-load="3" format="native" sizes-at-0="native" targeting-pos="native-article-related"
                targeting-native="native"></gpt-ad>
              <div class="ArticleRelatedContentList_content__1aQb6"
                data-view-action="view link - recommended reading 1 - item 3"
                data-view-label="https://www.theatlantic.com/magazine/archive/2021/04/the-internet-doesnt-have-to-be-awful/618079/">
                <figure class="ArticleRelatedContentList_figure__1M8iQ"><a class="ArticleRelatedContentList_link__mi83W"
                    href="https://www.theatlantic.com/magazine/archive/2021/04/the-internet-doesnt-have-to-be-awful/618079/"
                    title="Read More: How to Put Out Democracy’s Dumpster Fire"
                    data-action="click link - recommended reading - image 3"
                    data-label="https://www.theatlantic.com/magazine/archive/2021/04/the-internet-doesnt-have-to-be-awful/618079/">
                    <picture class="ArticleRelatedContentList_picture__Mv-vI"><img
                        src="https://cdn.theatlantic.com/thumbor/iB70YIv5LnzFHOinIWFxh97Cjq4=/438x0:1563x1125/90x90/media/img/2021/02/WEL_Applebaum_Opener/original.jpg"
                        srcset="https://cdn.theatlantic.com/thumbor/iB70YIv5LnzFHOinIWFxh97Cjq4=/438x0:1563x1125/90x90/media/img/2021/02/WEL_Applebaum_Opener/original.jpg 90w, https://cdn.theatlantic.com/thumbor/3sVKYT9kM9OJdLNTjQK8dQ-CfhU=/438x0:1563x1125/180x180/media/img/2021/02/WEL_Applebaum_Opener/original.jpg 180w"
                        alt="illustration with U.S. Founders and internet glitches" loading="lazy"
                        class="Image_root__J8Wlz Image_lazy__1w_jB Image_loaded__3uNg2 ArticleRelatedContentList_image__27aRm"
                        width="90" height="90"></picture>
                  </a></figure>
                <div class="ArticleRelatedContentList_textWrapper__3ABd5">
                  <h3 class="ArticleRelatedContentList_title__3A31L"><a class="ArticleRelatedContentList_link__mi83W"
                      href="https://www.theatlantic.com/magazine/archive/2021/04/the-internet-doesnt-have-to-be-awful/618079/"
                      data-action="click link - recommended reading - title 3"
                      data-label="https://www.theatlantic.com/magazine/archive/2021/04/the-internet-doesnt-have-to-be-awful/618079/">How
                      to Put Out Democracy’s Dumpster Fire</a></h3>
                  <address class="ArticleRelatedContentList_byline__2z0Zo"><a
                      href="https://www.theatlantic.com/author/anne-applebaum/"
                      data-action="click link - recommended reading - author 3"
                      data-label="https://www.theatlantic.com/author/anne-applebaum/"><span>Anne Applebaum</span></a>
                    and <a href="https://www.theatlantic.com/author/peter-pomerantsev/"
                      data-action="click link - recommended reading - author 3"
                      data-label="https://www.theatlantic.com/author/peter-pomerantsev/"><span>Peter
                        Pomerantsev</span></a></address>
                </div>
              </div>
            </li>
          </ul>
        </section>
      </div>
    </div>
    <p class="ArticleParagraph_root__2QM08">Unlike the <a href="https://perma.cc/K2SH-AY2E">briefly ascendant
        proprietary networks</a> such as CompuServe, AOL, and <a
        href="https://www.theatlantic.com/technology/archive/2014/07/where-online-services-go-when-they-die/374099/">Prodigy</a>,
      content and network would be separated. Indeed, the internet had and has no main menu, no CEO, no public stock
      offering, no formal organization at all. There are only engineers who meet every so often to refine its suggested
      communications protocols that hardware and software makers, and network builders, are then free to take up as they
      please.</p>
    <p class="ArticleParagraph_root__2QM08">So the internet was a recipe for mortar, with an invitation for anyone, and
      everyone, to bring their own bricks. Tim Berners-Lee took up the invite and invented the protocols for the World
      Wide Web, an application to run on the internet. If your computer spoke “web” by running a browser, then it could
      speak with servers that also spoke web, naturally enough known as websites. Pages on sites could contain links to
      all sorts of things that would, by definition, be but a click away, and might in practice be found at servers
      anywhere else in the world, hosted by people or organizations not only not affiliated with the linking webpage,
      but entirely unaware of its existence. And webpages themselves might be assembled from multiple sources before
      they displayed as a single unit, facilitating the rise of ad networks that could be called on by websites to
      insert surveillance beacons and ads on the fly, as pages were pulled together at the moment someone sought to view
      them.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-3" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">And like the internet’s own designers, Berners-Lee <a
        href="https://perma.cc/ZKL8-MTKL">gave away</a> his protocols to the world for free—enabling a design that
      omitted any form of centralized management or control, since there was no usage to track by a World Wide Web,
      Inc., for the purposes of billing. The web, like the internet, is a <a
        href="https://perma.cc/5FYL-GF5P">collective hallucination</a>, a set of independent efforts united by common
      technological protocols to appear as a seamless, magical whole.</p>
    <p class="ArticleParagraph_root__2QM08">This absence of central control, or even easy central monitoring, has long
      been celebrated as an instrument of grassroots democracy and freedom. It’s not trivial to censor a network as
      organic and decentralized as the internet. But more recently, these features have been understood to facilitate
      vectors for individual harassment and societal destabilization, with no easy gating points through which to remove
      or label malicious work not under the umbrellas of the major social-media platforms, or to quickly identify their
      sources. While both assessments have power to them, they each gloss over a key feature of the distributed web and
      internet: Their designs naturally create gaps of responsibility for maintaining valuable content that others rely
      on. Links work seamlessly until they don’t. And as tangible counterparts to online work fade, these gaps represent
      actual holes in humanity’s knowledge.</p>
    <hr class="ArticleLegacyHtml_root__3ONhH c-section-divider ArticleLegacyHtml_standard__1jFeZ">
    <p class="ArticleParagraph_root__2QM08">Before today’s internet, the primary way to preserve something for the ages
      was to consign it to writing—first on stone, then parchment, then papyrus, then 20-pound acid-free paper, then a
      tape drive, floppy disk, or hard-drive platter—and store the result in a temple or library: a <a
        href="https://perma.cc/7EWD-9LHS?type=image">building designed to guard it</a> against rot, theft, war, and
      natural disaster. This approach has facilitated preservation of some material for thousands of years. Ideally,
      there would be multiple identical copies stored in multiple libraries, so the failure of one storehouse wouldn’t
      extinguish the knowledge within. And in rare instances in which a document was surreptitiously altered, it could
      be compared against copies elsewhere to detect and correct the change.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-4" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">These buildings didn’t run themselves, and they weren’t mere warehouses.
      They were staffed with clergy and then librarians, who fostered a culture of preservation and its many elaborate
      practices, so precious documents would be both safeguarded and made accessible at scale—certainly physically, and,
      as important, through careful indexing, so an inquiring mind could be paired with whatever a library had that
      might slake that thirst. (As Jorge Luis Borges pointed out, <a
        href="https://www.theatlantic.com/technology/archive/2016/06/knowledge-compendia/485507/">a library without an
        index</a> becomes paradoxically <a href="https://perma.cc/5Y7B-KNXU">less informative</a> as it grows.)</p>
    <p class="ArticleParagraph_root__2QM08">At the dawn of the internet age, 25 years ago, it seemed the internet would
      make for immense improvements to, and perhaps some relief from, these stewards’ long work. The quirkiness of the
      internet and web’s design was the apotheosis of ensuring that the perfect would not be the enemy of the good.
      Instead of a careful system of designation of “important” knowledge distinct from day-to-day mush, and importation
      of that knowledge into the institutions and cultures of permanent preservation and access (libraries), there was
      just the infinitely variegated web, with canonical reference websites like those for academic papers and newspaper
      articles juxtaposed with PDFs, blogs, and social-media posts hosted here and there.</p>
    <p id="injected-recirculation-link-0" class="ArticleRelatedContentLink_root__1Ukm-"
      data-view-action="view link - injected link - item 1"><a
        href="https://www.theatlantic.com/technology/archive/2016/12/the-search-for-lost-knowledge/506879/">Adrienne
        LaFrance: Searching for lost knowledge in the age of intelligent machines</a></p>
    <p class="ArticleParagraph_root__2QM08">Enterprising students designed web crawlers to automatically follow and
      record every single link they could find, and then follow every link at the end of that link, and then build a
      concordance that would allow people to search across a seamless whole, creating search engines returning the top
      10 hits for a word or phrase among, today, more than 100 trillion possible pages. As Google <a
        href="https://perma.cc/9HE2-VZF9">puts it</a>, “The web is like an ever-growing library with billions of books
      and no central filing system.”</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-5" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Now, I just quoted from Google’s corporate website, and I used a hyperlink
      so you can see my source. Sourcing is the glue that holds humanity’s knowledge together. It’s what allows you to
      learn more about what’s only briefly mentioned in an article like this one, and for others to double-check the
      facts as I represent them to be. The link I used points to <a
        href="https://www.google.com/search/howsearchworks/crawling-indexing/">https://www.google.com/search/howsearchworks/crawling-indexing/</a>.
      Suppose Google were to change what’s on that page, or reorganize its website anytime between when I’m writing this
      article and when you’re reading it, eliminating it entirely. Changing what’s there would be an example of content
      drift; eliminating it entirely is known as <a href="https://perma.cc/WBM7-WD23">link rot</a>.</p>
    <p class="ArticleParagraph_root__2QM08">It turns out that link rot and content drift are <a
        href="https://www.theatlantic.com/technology/archive/2015/10/raiders-of-the-lost-web/409210/">endemic to the
        web</a>, which is both unsurprising and shockingly risky for a library that has “billions of books and no
      central filing system.” Imagine if libraries didn’t exist and there was only a “sharing economy” for physical
      books: People could register what books they happened to have at home, and then others who wanted them could visit
      and peruse them. It’s no surprise that such a system could fall out of date, with books no longer where they were
      advertised to be—especially if someone reported a book being in someone else’s home in 2015, and then an
      interested reader saw that 2015 report in 2021 and tried to visit the original home mentioned as holding it.
      That’s what we have right now on the web.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-6" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Whether humble home or massive government edifice, hosts of content can and
      do fail. For example, President Barack Obama signed the Affordable Care Act in the spring of 2010. In the fall of
      2013, congressional Republicans shut down day-to-day government funding in an attempt to kill Obamacare. Federal
      agencies, obliged to cease all but essential activities, pulled the plug on websites across the U.S. government,
      including access to thousands, perhaps millions, of official government documents, both current and archived, and
      of course very few having anything to do with Obamacare. As night follows day, every single link pointing to the
      affected documents and sites no longer worked. Here’s NASA’s website from the time:</p>
    <div class="ArticleInlineImageFigure_root__GE0ZY ArticleInlineImageFigure_alignWell__SmfWG">
      <figure class="ArticleInlineImageFigure_figure__1dCVd" style="--imageWidth:624px;max-width:624px">
        <picture class="ArticleInlineImageFigure_picture__2IguK" style="padding-bottom: 57.21%;"><img
            src="https://lh6.googleusercontent.com/2CUDyR8ziF3a3zgAsLJvs9wbNM6MTGJWaAiY3vNF4YtpGHqo_2Lf05OMF52afJi9fedLMRx7yEnWqPMHMJbj8FIAo5mvaLe4Z35YKyG3awoNM5DfPLKG83sZQN_u8NcDieE7cr8"
            srcset="https://lh6.googleusercontent.com/2CUDyR8ziF3a3zgAsLJvs9wbNM6MTGJWaAiY3vNF4YtpGHqo_2Lf05OMF52afJi9fedLMRx7yEnWqPMHMJbj8FIAo5mvaLe4Z35YKyG3awoNM5DfPLKG83sZQN_u8NcDieE7cr8"
            alt="" loading="lazy"
            class="Image_root__J8Wlz Image_lazy__1w_jB Image_loaded__3uNg2 ArticleInlineImageFigure_image__3Z6hd"
            width="624" height="357"></picture>
      </figure>
    </div>
    <p class="ArticleParagraph_root__2QM08">In 2010, Justice Samuel Alito wrote a concurring opinion in a case before
      the Supreme Court, and his opinion linked to a website as part of the explanation of his reasoning. Shortly after
      the opinion was released, anyone following the link wouldn’t see whatever it was Alito had in mind when writing
      the opinion. Instead, they would find this <a href="https://perma.cc/0gwuqRxEJJW?type=image">message</a>: “Aren’t
      you glad you didn’t cite to this webpage … If you had, like Justice Alito did, the original content would have
      long since disappeared and someone else might have come along and purchased the domain in order to make a comment
      about the transience of linked information in the internet age.”</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-7" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Inspired by cases like these, some colleagues and I joined those
      investigating the extent of link rot in 2014 and again this past spring.</p>
    <p class="ArticleParagraph_root__2QM08">The <a href="https://perma.cc/KL84-CEHS">first study</a>, with Kendra Albert
      and Larry Lessig, focused on documents meant to endure indefinitely: links within scholarly papers, as found in
      the <em>Harvard Law Review</em>, and judicial opinions of the Supreme Court. We found that 50 percent of the links
      embedded in Court opinions since 1996, when the first hyperlink was used, no longer worked. And 75 percent of the
      links in the <em>Harvard Law Review</em> no longer worked.</p>
    <p class="ArticleParagraph_root__2QM08">People tend to overlook the decay of the modern web, when in fact these
      numbers are extraordinary—they represent a comprehensive breakdown in the chain of custody for facts. Libraries
      exist, and they still have books in them, but they aren’t stewarding a huge percentage of the information that
      people are linking to, including within formal, legal documents. No one is. The flexibility of the web—the very
      feature that makes it work, that had it eclipse CompuServe and other centrally organized networks—diffuses
      responsibility for this core societal function.</p>
    <p id="injected-recirculation-link-1" class="ArticleRelatedContentLink_root__1Ukm-"
      data-view-action="view link - injected link - item 2"><a
        href="https://www.theatlantic.com/technology/archive/2015/10/raiders-of-the-lost-web/409210/">Read: Raiders of
        the lost web</a></p>
    <p class="ArticleParagraph_root__2QM08">The problem isn’t just for academic articles and judicial opinions. With
      John Bowers and Clare Stanton, and the kind cooperation of <em>The New York Times</em>, I was able to analyze
      approximately 2 million externally facing links found in articles at nytimes.com since its inception in 1996. We
      found that 25 percent of deep links have rotted. (<a
        href="https://www.theatlantic.com/technology/archive/2017/04/a-search-for-the-zombie-websites-of-1995/523848/">Deep
        links</a> are links to specific content—think theatlantic.com/article, as opposed to just theatlantic.com.) The
      <a href="https://perma.cc/SQ9W-X9AY">older the article</a>, the less likely it is that the links work. If you go
      back to 1998, 72 percent of the links are dead. Overall, more than half of all articles in <em>The New York
        Times</em> that contain deep links have at least one rotted link.
    </p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-8" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Our studies are in line with others. As far back as 2001, a team at
      Princeton University studied the <a href="https://perma.cc/3F3K-4T2L">persistence of web references in scientific
        articles</a>, finding that the raw number of URLs contained in academic articles was increasing but that many of
      the links were broken, including 53 percent of those in the articles they had collected from 1994. Thirteen years
      later, six researchers created a data set of more than 3.5 million scholarly articles about science, technology,
      and medicine, and determined that <a href="https://perma.cc/66MA-JLM5">one in five</a> no longer points to its
      originally intended source. In 2016, an analysis with the same data set <a href="https://perma.cc/Q54B-XHJV">found
        that 75 percent of all references</a> had drifted.</p>
    <p class="ArticleParagraph_root__2QM08">Of course, there’s a keenly related problem of permanency for much of what’s
      online. People communicate in ways that feel ephemeral and let their guard down commensurately, only to find that
      a Facebook comment can stick around forever. The upshot is the worst of both worlds: Some information sticks
      around when it shouldn’t, while other information vanishes when it should remain.</p>
    <hr class="ArticleLegacyHtml_root__3ONhH c-section-divider ArticleLegacyHtml_standard__1jFeZ">
    <p class="ArticleParagraph_root__2QM08">So far, the rise of the web has led to routinely cited sources of
      information that aren’t part of more formal systems; blog entries or casually placed working papers at some
      particular web address have no counterparts in the pre-internet era. But surely anything truly worth keeping for
      the ages would still be published as a book or an article in a scholarly journal, making it accessible to today’s
      libraries, and preservable in the same way as before? Alas, no.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-9" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Because information is so readily placed online, the incentives for creating
      paper counterparts, and storing them in the traditional ways, declined slowly at first and have since plummeted.
      Paper copies were once considered originals, with any digital complement being seen as a bonus. But now, both
      publisher and consumer—and libraries that act in the long term on behalf of their consumer patrons—see digital as
      the primary vehicle for access, and paper copies are deprecated.</p>
    <p class="ArticleParagraph_root__2QM08">From my vantage point as a law professor, I’ve seen the last people ready to
      turn out the lights at the end of the party: the law-student editors of academic law journals. One of the more
      stultifying rites of passage for entering law students is to “subcite,” checking the citations within scholarship
      in progress to make sure they are in the exacting and byzantine form required by legal-citation standards, and,
      more directly, to make sure the source itself exists and says what the citing author says it says. (In a somewhat
      alarming number of instances, it does not, which is a good reason to entertain the subciting exercise.)</p>
    <p class="ArticleParagraph_root__2QM08">The original practice for, say, the <em>Harvard Law Review</em>, was to
      require a student subciter to lay eyes on an original paper copy of the cited source, such as a statute or a
      judicial opinion. The Harvard Law Library would, in turn, endeavor to keep a physical copy of everything—ideally
      every law and case from everywhere—for just that purpose. The <em>Law Review</em> has since eased up, allowing
      digital images of printed text to suffice, and that’s not entirely unwelcome: It turns out that the physical law
      (as distinct from the laws of physics) takes up a lot of space, and Harvard Law School was sending more and more
      books out to a remote depository, to be laboriously retrieved when needed.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-10" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">A few years ago I <a href="https://perma.cc/RMR3-8LXL">helped lead</a> <a
        href="https://perma.cc/9MG8-SGPM">an effort to digitize all of that paper</a> both as images and as searchable
      text—more than 40,000 volumes comprising more than 40 million pages—which completed the scanning of nearly every
      published case from every state from the time of that state’s inception up through the end of 2018. (The scanned
      books have been <a href="https://perma.cc/D9TA-ZKHT">sent to an abandoned limestone mine </a>in Kentucky, as a
      hedge against some kind of digital or even physical apocalypse.)</p>
    <p class="ArticleParagraph_root__2QM08">A special quirk allowed us to do that scanning, and to then treat the
      longevity of the result as seriously as we do that of any printed material: American case law is not copyrighted,
      because it’s the product of judges. (Indeed, any work by the U.S. government is <a
        href="https://perma.cc/XJ3S-2FGN">required by statute</a> to be in the public domain.) But the Harvard Law
      School library is no longer collecting the print editions from which to scan—it’s too expensive. And other printed
      materials are essentially trapped on paper until copyright law is refined to better account for digital
      circumstances.</p>
    <p class="ArticleParagraph_root__2QM08">Into that gap has entered material that’s born digital, offered by the same
      publishers that would previously have been selling on printed matter. But there’s a catch: These officially
      sanctioned digital manifestations of material have an asterisk next to their permanence. Whether it’s an
      individual or a library acquiring them, the purchaser is typically buying mere access to the material for a
      certain period of time, without the ability to transfer the work into the purchaser’s own chosen container. This
      is true of many commercially published scholarly journals, for which “subscription” no longer signifies a regular
      delivery of paper volumes that, if canceled, simply means no more are forthcoming. Instead, subscription is for
      ongoing access to the entire corpus of journals hosted by the publishers themselves. If the subscription
      arrangement is severed, the entire oeuvre becomes inaccessible.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-11" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Libraries in these scenarios are no longer custodians for the ages of
      anything, whether tangible or intangible, but rather poolers of funding to pay for fleeting access to knowledge
      elsewhere.</p>
    <p class="ArticleParagraph_root__2QM08">Similarly, books are now often purchased on Kindles, which are the Hotel
      Californias of digital devices: They enter but can’t be extracted, except by Amazon. Purchased books can be
      involuntarily zapped by Amazon, which has been known to do so, refunding the original purchase price. For example,
      10 years ago, a third-party bookseller offered a well-known book in Kindle format on Amazon for 99 cents a copy,
      mistakenly thinking it was no longer under copyright. Once the error was noted, Amazon—in something of a
      panic—reached into every Kindle that had downloaded the book and <a href="https://perma.cc/7MVA-SRH8">deleted
        it</a>. The book was, fittingly enough, George Orwell’s <em>1984</em>. (<em>You don’t have </em>1984<em>. In
        fact, you never had </em>1984<em>. There is no such book as </em>1984<em>.</em>)</p>
    <p class="ArticleParagraph_root__2QM08">At the time, the incident was seen as evocative but not truly worrisome;
      after all, plenty of physical copies of <em>1984</em> were available. Today, as both individual and library book
      buying shifts from physical to digital, a de-platforming of a Kindle book—including a retroactive one—can carry
      much more weight.</p>
    <p id="injected-recirculation-link-2" class="ArticleRelatedContentLink_root__1Ukm-"
      data-view-action="view link - injected link - item 3"><a
        href="https://www.theatlantic.com/magazine/archive/2019/07/1984-george-orwell/590638/">George Packer: What
        ‘1984’ means today</a></p>
    <p class="ArticleParagraph_root__2QM08">Deletion isn’t the only issue. Not only can information be removed, but it
      also can be changed. Before the advent of the internet, it would have been futile to try to change the contents of
      a book after it had been long published. Librarians do not take kindly to someone attempting to rip out or mark up
      a few pages of an “incorrect” book. The closest approximation of post-hoc editing would have been to influence the
      contents of a later edition.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-12" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Ebooks don’t have those limitations, both because of how readily new
      editions can be created and how simple it is to push “updates” to existing editions after the fact. Consider the
      <a href="https://perma.cc/W4B2-QRXR">experience</a> of Philip Howard, who sat down to read a printed edition of
      <em>War and Peace</em> in 2010. Halfway through reading the brick-size tome, he purchased a 99-cent electronic
      edition for his Nook e-reader:
    </p>
    <div class="ArticleLegacyHtml_root__3ONhH ArticleLegacyHtml_standard__1jFeZ">
      <blockquote class="">
        <p>As I was reading, I came across this sentence: “It was as if a light had been Nookd in a carved and painted
          lantern …” Thinking this was simply a glitch in the software, I ignored the intrusive word and continued
          reading. Some pages later I encountered the rogue word again. With my third encounter I decided to retrieve my
          hard cover book and find the original (well, the translated) text.</p>
        <p>For the sentence above I discovered this genuine translation: “It was as if a light had been kindled in a
          carved and painted lantern …”</p>
      </blockquote>
    </div>
    <p class="ArticleParagraph_root__2QM08">A search of this Nook version of the book confirmed it: Every instance of
      the word <em>kindle</em> had been replaced by <em>nook</em>, in perhaps an attempt to alter a previously made
      Kindle version of the book for Nook use. Here are some screenshots <a
        href="http://futureoftheinternet.org/2012/06/01/war-and-nookd/">I took</a> at the time:</p>
    <div class="ArticleInlineImageFigure_root__GE0ZY ArticleInlineImageFigure_alignWell__SmfWG">
      <figure class="ArticleInlineImageFigure_figure__1dCVd" style="--imageWidth:200px;max-width:200px">
        <picture class="ArticleInlineImageFigure_picture__2IguK" style="padding-bottom: 150%;"><img
            src="https://cdn.theatlantic.com/thumbor/6lH62JZjSAODBUM9kI6J03DhOK0=/filters:format(png)/media/img/posts/2021/06/IMG_1324_200x300/original.png"
            srcset="https://cdn.theatlantic.com/thumbor/6lH62JZjSAODBUM9kI6J03DhOK0=/filters:format(png)/media/img/posts/2021/06/IMG_1324_200x300/original.png"
            alt="A screenshot of the word &quot;kindle&quot; being replaced by &quot;nook&quot;" loading="lazy"
            class="Image_root__J8Wlz Image_lazy__1w_jB Image_loaded__3uNg2 ArticleInlineImageFigure_image__3Z6hd"
            width="200" height="300"></picture>
      </figure>
    </div>
    <p class="ArticleParagraph_root__2QM08"></p>
    <div class="ArticleInlineImageFigure_root__GE0ZY ArticleInlineImageFigure_alignCenter__2QVLC">
      <figure class="ArticleInlineImageFigure_figure__1dCVd" style="--imageWidth:200px;max-width:200px">
        <picture class="ArticleInlineImageFigure_picture__2IguK" style="padding-bottom: 150%;"><img
            src="https://cdn.theatlantic.com/thumbor/42BrllbMxgXiuvzNVuk4XQBzhBY=/filters:format(png)/media/img/posts/2021/06/IMG_1322_200x300/original.png"
            srcset="https://cdn.theatlantic.com/thumbor/42BrllbMxgXiuvzNVuk4XQBzhBY=/filters:format(png)/media/img/posts/2021/06/IMG_1322_200x300/original.png"
            alt="Screenshot from Nook" loading="lazy"
            class="Image_root__J8Wlz Image_lazy__1w_jB Image_loaded__3uNg2 ArticleInlineImageFigure_image__3Z6hd"
            width="200" height="300"></picture>
      </figure>
    </div>
    <p class="ArticleParagraph_root__2QM08">It is only a matter of time before the retroactive malleability of these
      forms of publishing becomes a new area of pressure and regulation for content censorship. If a book contains a
      passage that someone believes to be defamatory, the aggrieved person can sue over it—and receive monetary damages
      if they’re right. Rarely is the book’s existence itself called into question, if only because of the difficulty of
      putting the cat back into the bag after publishing.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-13" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Now it’s far easier to make demands for a refinement or an outright change
      of the offending sentence or paragraph. So long as those remedies are no longer fanciful, the terms of a
      settlement can include them, as well as a promise not to advertise that a change has even been made. And a lawsuit
      need never be filed; only a demand made, publicly or privately, and not one grounded in a legal claim, but simply
      one of outrage and potential publicity. Rereading an old Kindle favorite might then become reading a slightly (if
      momentously) tweaked version of that old book, with only a nagging feeling that it isn’t quite how one remembers
      it.</p>
    <p class="ArticleParagraph_root__2QM08">This isn’t hypothetical. This month, the best-selling author Elin
      Hilderbrand published a new novel. The novel, widely praised by critics, included a snippet of dialogue in which
      one character makes a wry joke to another about spending the summer in an attic on Nantucket, “like Anne Frank.”
      Some readers <a href="https://perma.cc/8R58-A4KQ">took to social media</a> to criticize this moment between
      characters as anti-Semitic. The author sought to explain the character’s use of the analogy before offering an
      apology and saying that she had asked her publisher to remove the passage from digital versions of the book
      immediately.</p>
    <p class="ArticleParagraph_root__2QM08">There are sufficient technical and typographical alterations to ebooks after
      they’re published that a publisher itself might not even have a simple accounting of how often it, or one of its
      authors, has been importuned to alter what has already been published. Nearly 25 years ago I helped Wendy Seltzer
      start a site, now called <a href="https://perma.cc/9SW6-L7VA">Lumen</a>, that tracks requests for elisions from
      institutions <a href="https://perma.cc/8QQ5-RRH9">ranging from</a> the University of California to the Internet
      Archive to Wikipedia, Twitter, and Google—often for claimed copyright infringements found by clicking through
      links published there. Lumen thus makes it possible to learn more about what’s missing or changed from, say, a
      Google web search, because of outside demands or requirements.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-14" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">For example, thanks to the site’s record-keeping both of deletions and of
      the source and text of demands for removals, the law professor Eugene Volokh was able to identify a number of
      removal requests made <a href="https://perma.cc/5ZC2-P4JM">with fraudulent documentation</a>—nearly 200 out of 700
      “court orders” submitted to Google that he reviewed turned out to have been apparently Photoshopped from whole
      cloth. The Texas attorney general has since <a href="https://perma.cc/JA33-F7F9?type=image">sued</a> a company for
      routinely submitting these falsified court orders to Google for the purpose of forcing content removals. Google’s
      relationship with Lumen is purely voluntary—YouTube, which, like Google, has the parent company Alphabet, is not
      currently sending notices. Removals through other companies—like book publishers and distributors such as
      Amazon—are not publicly available.</p>
    <p class="ArticleParagraph_root__2QM08">The rise of the Kindle points out that even the concept of a link—a “uniform
      resource locator,” or URL—is under great stress. Since Kindle books don’t live on the World Wide Web, there’s no
      URL pointing to a particular page or passage of them. The same goes for content within any number of mobile apps,
      leaving people to trade screenshots—or, as <em>The Atlantic</em>’s Kaitlyn Tiffany <a
        href="https://www.theatlantic.com/technology/archive/2021/06/screenshots-gremlins-internet/619062/">put it</a>,
      “the gremlins of the internet”—as a way of conveying content.</p>
    <p class="ArticleParagraph_root__2QM08">Here, courtesy of the law professor <a
        href="https://perma.cc/Y2AP-6CBR">Alexandra Roberts</a>, is how a district-court <a
        href="https://perma.cc/5FZC-L9CR">opinion</a> pointed to a TikTok video: “A May 2020 TikTok video featuring the
      Reversible Octopus Plushies now has over 1.1 million likes and 7.8 million views. The video can be found at
      Girlfriends mood #teeturtle #octopus #cute #verycute #animalcrossing #cutie #girlfriend #mood #inamood
      #timeofmonth #chocolate #fyp #xyzcba #cbzzyz #t (tiktok.com).”</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-15" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">Which brings us full circle to the fact that long-term writing, including
      official documents, might often need to point to short-term, noncanonical sources to establish what they mean to
      say—and the means of doing that is disintegrating before our eyes (or worse, entirely unnoticed). And even
      long-term, canonical sources such as books and scholarly journals are in fugacious configurations—usually to
      support digital subscription models that require scarcity—that preclude ready long-term linking, even as their
      physical counterparts evaporate.</p>
    <hr class="ArticleLegacyHtml_root__3ONhH c-section-divider ArticleLegacyHtml_standard__1jFeZ">
    <p class="ArticleParagraph_root__2QM08">The project of preserving and building on our intellectual track, including
      all its meanderings and false starts, is thus falling victim to the catastrophic success of the digital revolution
      that should have bolstered it. Tools that could have made humanity’s knowledge production available to all instead
      have, for completely understandable reasons, militated toward an ever-changing “now,” where there’s no easy way to
      cite many sources for posterity, and those that are citable are all too mutable.</p>
    <p class="ArticleParagraph_root__2QM08">Again, the stunning success of the improbable, eccentric architecture of our
      internet came about because of a wise decision to favor the good over the perfect and the general over the
      specific. I have admiringly called this the “<a href="https://perma.cc/2NP9-CTUS">Procrastination Principle</a>,”
      wherein an elegant network design would not be unduly complicated by attempts to solve every possible problem that
      one could imagine materializing in the future. We see the <a
        href="http://yupnet.org/zittrain/2008/03/01/chapter-6-the-lessons-of-wikipedia/#27">principle at work</a> in
      Wikipedia, where the initial pitch for it would seem preposterous: “We can generate a consummately thorough and
      mostly reliable encyclopedia by allowing anyone in the world to create a new page and anyone else in the world to
      drop by and revise it.”</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-16" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">It would be natural to immediately ask what would possibly motivate anyone
      to contribute constructively to such a thing, and what defenses there might be against edits made ignorantly or in
      bad faith. If Wikipedia garnered enough activity and usage, wouldn’t some two-bit vendor be motivated to turn
      every article into a spammy ad for a Rolex watch?</p>
    <p class="ArticleParagraph_root__2QM08">Indeed, Wikipedia suffers from vandalism, and over time, its sustaining
      community has developed tools and practices for dealing with it that didn’t exist when Wikipedia was created. If
      they’d been implemented too soon, the extra hurdles to starting and editing pages might have deterred many of the
      contributions that got Wikipedia going to begin with. The Procrastination Principle paid off.</p>
    <p class="ArticleParagraph_root__2QM08">Similarly, it wasn’t on the web inventor Tim Berners-Lee’s mind to vet
      proposed new websites according to any standard of truth, reliability, or … anything else. People could build and
      offer whatever they wanted, so long as they had the hardware and connectivity to set up a web server, and others
      would be free to visit that site or ignore it as they wished. That websites would come and go, and that individual
      pages might be rearranged, was a feature, not a bug. Just as the internet could have been structured as a big
      CompuServe, centrally mediated, but wasn’t, the web could have had any number of features to better assure
      permanence and sourcing. Ted Nelson’s Xanadu project contemplated all that and more, including “<a
        href="https://perma.cc/QWJ4-H9PA">two-way links</a>” that would alert a site every time someone out there chose
      to link to it. But Xanadu <a href="https://perma.cc/7CGY-4GVB">never took off</a>.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-17" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">As procrastinators know, later doesn’t mean never, and the benefits of the
      internet and web’s flexibility—including permitting the building of walled app gardens on top of them that reject
      the idea of a URL entirely—now come at great risk and cost to the larger tectonic enterprise to, in Google’s <a
        href="https://www.theguardian.com/technology/2014/nov/03/larry-page-google-dont-be-evil-sergey-brin">early
        words</a>, “organize the world’s information and make it universally accessible and useful.”</p>
    <p class="ArticleParagraph_root__2QM08">Sergey Brin and Larry Page’s idea was a noble one—so noble that for it to be
      entrusted to a single company, rather than society’s long-honed institutions, such as libraries, would not do it
      justice. Indeed, when Google’s founders first released a <a href="https://perma.cc/8GDJ-K6AX">paper</a> describing
      the search engine they had invented, they included an appendix about “advertising and mixed motives,” concluding
      that “the issue of advertising causes enough mixed incentives that it is crucial to have a competitive search
      engine that is transparent and in the academic realm.” No such transparent, academic competitive search engine
      exists in 2021. By making the storage and organization of information everyone’s responsibility and no one’s, the
      internet and web could grow, unprecedentedly expanding access, while making any and all of it fragile rather than
      robust in many instances in which we depend on it.</p>
    <hr class="ArticleLegacyHtml_root__3ONhH c-section-divider ArticleLegacyHtml_standard__1jFeZ">
    <p class="ArticleParagraph_root__2QM08">What are we going to do about the crisis we’re in? No one is more keenly
      aware of the problem of the internet’s ephemerality than Brewster Kahle, a technologist who founded the Internet
      Archive in 1996 as a nonprofit effort to preserve humanity’s knowledge, especially and including the web. Brewster
      had developed a precursor to the web called WAIS, and then a web-traffic-measurement platform called Alexa,
      eventually bought by Amazon. That sale put Brewster in a position personally to help fund the Internet Archive’s
      initial operations, including the <a href="https://perma.cc/XJ5J-YUDM">Wayback Machine</a>, specifically designed
      to collect, save, and make available webpages even after they’ve gone away. It did this by picking multiple entry
      points to start “scraping” pages—saving their contents rather than merely displaying them in a browser for a
      moment—and then following as many successive links as possible on those pages, and those pages’ linked pages.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-18" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">It is no coincidence that a single civic-minded citizen like Brewster was
      the one to step up, instead of our existing institutions. In part that’s due to potential legal risks that tend to
      slow down or deter well-established organizations. The copyright implications of crawling, storing, and displaying
      the web were at first unsettled, typically leaving such actions either to parties who could be low key about it,
      saving what they scraped only for themselves; to large and powerful commercial parties like search engines whose
      business imperatives made showing only the most recent, active pages central to how they work; or to tech-oriented
      individuals with a start-up mentality and little to lose. An example of the latter is at work with Clearview AI,
      where a single rakish entrepreneur <a href="https://perma.cc/C9T4-XWVQ">scraped billions of images and tags</a>
      from social-networking sites such as Facebook, LinkedIn, and Instagram in order to build a facial-recognition
      database capable of identifying nearly any photo or video clip of someone.</p>
    <p class="ArticleParagraph_root__2QM08">Brewster is superficially in that category, too, but—in the spirit of the
      internet and web’s inventors—is doing what he’s doing because he believes in his work’s virtue, not its financial
      potential. The Wayback Machine’s approach is to save as much as possible as often as possible, and in practice
      that means a lot of things every so often. That’s vital work, and it should be supported much more, whether with
      government subsidy or more foundation support. (The Internet Archive was <a href="https://perma.cc/34GY-LCT5">a
        semifinalist</a> for the MacArthur Foundation’s “<a href="https://www.100andchange.org/">100 and Change</a>”
      initiative, which awards $100 million individually to worthy causes.)</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-19" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">A complementary approach to “save everything” through independent scraping
      is for whoever is creating a link to make sure that a copy is saved at the time the link is made. Researchers at
      the <a href="https://perma.cc/VR8D-YQ23">Berkman Klein Center for Internet &amp; Society</a>, which I co-founded,
      <a href="https://perma.cc/D78K-3A3M">designed such a system</a> with an open-source package called <a
        href="https://perma.cc/SR95-M3VC">Amberlink</a>. The internet and the web invite any form of additional building
      on them, since no one formally approves new additions. Amberlink can run on some web servers to make it so that
      what’s at the end of a link can be captured when a webpage on an Amberlink-empowered server first includes that
      link. Then, when someone clicks on a link on an Amber-tuned site, there’s an opportunity to see what the site had
      captured at that link, should the original destination no longer be available. (Search engines such as Google have
      this feature, too—you can often <a href="https://support.google.com/websearch/answer/1687222?hl=en">ask</a> to see
      the search engine’s “cached” copy of a webpage linked from a search-results page, rather than just following the
      link to try to see the site yourself.)
    </p>
    <p class="ArticleParagraph_root__2QM08">Amber is an example of one website archiving another, unrelated website to
      which it links. It’s also possible for websites to archive themselves for longevity. In 2020, the Internet Archive
      announced a <a href="https://perma.cc/D4A7-JKFG">partnership</a> with a company called Cloudflare, which is used
      by popular or controversial websites to be more resilient against denial-of-service attacks conducted by bad
      actors that could make the sites unavailable to everyone. Websites that enable an “always online” service will see
      their content automatically archived by the Wayback Machine, and if the original host becomes unavailable to
      Cloudflare, the Internet Archive’s saved copy of the page will be made available instead.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-20" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">These approaches work generally, but they don’t always work specifically.
      When a judicial opinion, scholarly article, or editorial column points to a site or page, the author tends to have
      something very distinct in mind. If that page is changing—and there’s no way to know if it will change—then a 2021
      citation to a page isn’t reliable for the ages if the nearest copy of that page available is one archived in 2017
      or 2024.</p>
    <p class="ArticleParagraph_root__2QM08">Taking inspiration from Brewster’s work, and indeed partnering with the
      Internet Archive, I worked with <a href="https://lil.law.harvard.edu/about/">researchers</a> at Harvard’s <a
        href="https://perma.cc/96G3-ED45">Library Innovation Lab</a> to start <a
        href="https://perma.cc/29EV-7QA4">Perma</a>. Perma is an alliance of more than 150 libraries. Authors of
      enduring documents—including scholarly papers, newspaper articles, and judicial opinions—can ask Perma to convert
      the links included within them into permanent ones archived at <a href="http://perma.link">http://perma.cc</a>;
      participating libraries treat snapshots of what’s found at those links as accessions to their collections, and
      undertake to preserve them indefinitely.</p>
    <p class="ArticleParagraph_root__2QM08">In turn, the researchers Martin Klein, Shawn Jones, Herbert Van de Sompel,
      and Michael Nelson have honed a service called <a href="https://perma.cc/2P2Z-Q8ZS">Robustify</a> to allow
      archives of links from whatever source, including Perma, to be incorporated into new “dual-purpose” links so that
      they can point to a page that works in the moment, while also offering an archived alternative if the original
      page fails. That could allow for a rolling directory of snapshots of links from a variety of archives—a networked
      history that is both prudently distributed, internet-style, while shepherded by the long-standing institutions
      that have existed for this vital public-interest purpose: libraries.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-21" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">A technical infrastructure through which authors and publishers can preserve
      the links they draw on is a necessary start. But the problem of digital malleability extends beyond the technical.
      The law should hesitate before allowing the scope of remedies for claimed infringements of rights—whether economic
      ones such as copyright or more personal, dignitary ones such as defamation—to expand naturally as the ease of
      changing what’s already been published increases.</p>
    <p class="ArticleParagraph_root__2QM08">Compensation for harm, or the addition of corrective material, should be
      favored over quiet retroactive alteration. And publishers should establish clear and principled policies against
      undertaking such changes under public pressure that falls short of a legal finding of infringement. (And, in
      plenty of cases, publishers should stand up against legal pressure, too.)</p>
    <p class="ArticleParagraph_root__2QM08">The benefit of retroactive correction in some instances—imagine fixing a
      typographical error in the proportions of a recipe, or blocking out someone’s phone number shared for the purposes
      of harassment—should be contextualized against the prospect of systemic, chronic demands for revisions by
      aggrieved people or companies single-mindedly demanding changes that serve to eat away at the public record. The
      public’s interest in seeing what’s changed—or at least being aware that a change has been made and why—is as
      legitimate as it is diffuse. And because it’s diffuse, few people are naturally in a position to speak on its
      behalf.</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-22" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">For those times when censorship is deemed the right course, meticulous
      records should be kept of what has been changed. Those records should be available to the public, the way that
      Lumen’s records of copyright takedowns in Google search are, unless that very availability defeats the purpose of
      the elision. For example, to date, Google does not report to Lumen when it removes a negative entry in a web
      search about someone who has invoked Europe’s “right to be forgotten,” lest the public merely consult Lumen to see
      the very material that has been found under European law to be an undue drag on someone’s reputation (balanced
      against the public’s right to know).</p>
    <p class="ArticleParagraph_root__2QM08">In those cases, there should be a means of record-keeping that, while
      unavailable to the public in just a few clicks, should be available to researchers wanting to understand the
      dynamics of online censorship. John Bowers, Elaine Sedenberg, and I have described <a
        href="https://perma.cc/4UAQ-4HMX">how that might work</a>, suggesting that libraries can again serve as
      semi-closed archives of both public and private censorial actions online. We can build what the Germans used to
      call a <em>giftschrank</em>, a “poison cabinet” containing dangerous works that nonetheless should be preserved
      and accessible in certain circumstances. (Art imitates life: There is a “<a
        href="https://perma.cc/SW3J-NZC7">restricted section</a>” in Harry Potter’s universe, and an aptly named “<a
        href="https://perma.cc/A9HL-87X7">poison room</a>” in the television adaptation of <em>The Magicians</em>.)</p>
    <gpt-ad class="GptAd_root__nza6l ArticleInjector_root__8EeBf s-native s-native--standard s-native--streamline"
      format="injector" sizes-at-0="mobile-wide,native" targeting-pos="csi-ad-23" sizes-at-976="desktop-wide,native">
    </gpt-ad>
    <p class="ArticleParagraph_root__2QM08">It is really tempting to cover for mistakes by pretending they never
      happened. Our technology now makes that alarmingly simple, and we should build in a little less efficiency, a
      little more inertia that previously provided for itself in ample qualities because of the nature of printed texts.
      Even the Supreme Court hasn’t been above a <a href="https://perma.cc/TRC8-X5XD">few retroactive tweaks</a> to
      inaccuracies in its edicts. As the law professor Jeffrey Fisher said after our colleague Richard Lazarus
      discovered changes, “In Supreme Court opinions, every word matters … When they’re changing the wording of
      opinions, they’re basically rewriting the law.”</p>
    <p class="ArticleParagraph_root__2QM08">On an immeasurably more modest scale, if this article has a mistake in it,
      we should all want an author’s or editor’s note at the bottom indicating where a correction has been applied and
      why, rather than that kind of quiet revision. (At least, I want that before I know just how embarrassing an error
      it might be, which is why we devise systems based on principle, rather than trying to navigate in the moment.)</p>
    <p class="ArticleParagraph_root__2QM08">Society can’t understand itself if it can’t be honest with itself, and it
      can’t be honest with itself if it can only live in the present moment. It’s long overdue to affirm and enact the
      policies and technologies that will let us see where we’ve been, including and especially where we’ve erred, so we
      might have a coherent sense of where we are and where we want to go.</p>
  </section>
  <div id="article-end" style="height:1px"></div>
  <div></div>
</article>